{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsblatt 6, Aufgabe 1\n",
    "## Gruppe AC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Teilaufgabe 1__ <br>\n",
    "- Anwendung der quadratische Fehlerfunktion:<br>\n",
    "$(T_\\mu-y_\\mu)^2 = (3-1)^2 = 4 $ <br>\n",
    "$(T_\\mu-y_\\mu)^2 = (2-1)^2 = 2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Teilaufgabe 3: cross entropy__ <br>\n",
    "__a)__ <br>\n",
    "$H_A(B) = \\sum_x B(x)\\cdot \\log_2 \\left(\\frac{1}{A(x)}\\right) $ <br>\n",
    "$H_A(B) = 0.5 \\cdot \\log_2(8) + 0.25 \\cdot \\log_2(2) + 0.125 \\cdot \\log_2(4) + 0.125 \\cdot \\log_2(8) = 2.375 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "__b)__ <br>\n",
    "$H_B(A) = \\sum_x A(x)\\cdot \\log_2 \\left(\\frac{1}{B(x)}\\right) $ <br>\n",
    "$H_B(A) = 0.125 \\cdot \\log_2(2) + 0.5 \\cdot \\log_2(4) + 0.25 \\cdot \\log_2(8) + 0.125 \\cdot \\log_2(8) = 2.250 $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ <br>\n",
    "$H_B(B) = H(B) = 1.75 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__d) Kullback-Leibler-Divergenz__ <br>\n",
    "$D_A(B) = H_A(B)-H(B) = 2.3750 - 1.75 = 0.625$ <br>\n",
    "$D_B(A) = H_B(A)-H(A) = 1.4062 - 1.75 = -0.3438$ <br>\n",
    "$D_B(B) = H_B(B)-H(B) = 1.75 - 1.75 = 0$ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Teilaufgabe 4__:<br>\n",
    "$I: d_Q(P) \\geq 0 \\quad\\forall Q,P \\in X$ <br>\n",
    "Nach der Gibbs-Ungleichung gilt zunächst $\\sum_x P(x) = \\sum_x Q(x) = 1$ und weiterhin $-\\sum_x P(x)\\cdot \\log_2(P(x)) \\leq -\\sum_x P(x)\\cdot \\log_2 Q(x)$ <br>\n",
    "Daraus folgt <br>\n",
    "\\begin{align*}\n",
    "-\\sum_x P(x)\\cdot \\log_2(P(x))  &\\leq -\\sum_x P(x)\\cdot \\log_2(Q(x)) \\\\\n",
    "\\sum_x P(x)\\cdot \\log_2(1) - \\sum_x P(x)\\cdot \\log_2(P(x))   &\\leq \\sum_x P(x)\\cdot \\log_2(1) -\\sum_x P(x)\\cdot \\log_2(Q(x)) \\\\\n",
    "\\sum_x P(x)\\cdot \\log_2\\left(\\frac{1}{P(x)}\\right)   &\\leq    \\sum_x P(x)\\cdot \\log_2\\left(\\frac{1}{Q(x)}\\right) \\\\\n",
    "0 &\\leq   \\sum_x P(x)\\cdot \\log_2\\left(\\frac{1}{Q(x)}\\right)  - \\sum_x P(x)\\cdot \\log_2\\left(\\frac{1}{P(x)}\\right) \\\\\n",
    "0 &\\leq  H_Q(P) - H(P) = D_Q(P)\n",
    "\\end{align*}\n",
    "<br>\n",
    "<br>\n",
    "$III: d_Q(Q) = 0 \\quad \\forall Q\\in X$\n",
    "\\begin{align*}\n",
    "D_Q(Q) &= H_Q(Q) - H(Q) \\\\\n",
    "        &= \\sum_x Q(x)\\cdot \\log_2\\left(\\frac{1}{Q(x)}\\right) - \\sum_x Q(x)\\cdot \\log_2\\left(\\frac{1}{Q(x)}\\right) \\\\\n",
    "        &= 0\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Teilaufgabe 5__ <br>\n",
    "Das Minimum wird für C(x) = B(x) erwartet, d.h. $t=\\frac{2}{3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math as ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divergenz(C,B):\n",
    "    # D_C(B) = H_C(B) - H(B)\n",
    "    HB = 1.75\n",
    "    \n",
    "    HCB = 0\n",
    "    for i in range(0,4):\n",
    "        HCB = HCB + B[i]* ma.log2(1/C[i])\n",
    "    return HCB - HB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = [0.5, 0.25, 0.125, 0.125]\n",
    "\n",
    "t_start = 0.01\n",
    "t_end   = 0.99\n",
    "dt      = 0.01\n",
    "\n",
    "tValues = np.array(np.arange(t_start, t_end+dt, dt))\n",
    "KLdivergences = np.zeros(99)\n",
    "for i in range(99):\n",
    "    C = [tValues[i]*0.75, (1-tValues[i])*0.75, 0.125, 0.125]\n",
    "    KLdivergences[i] = divergenz(C,bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a6ceda5fd64ad9a9e8fec3b31d1025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(tValues, KLdivergences)\n",
    "plt.xlabel('$t$')\n",
    "plt.ylabel('$D_C(B)$')\n",
    "plt.title('Changige the code of Charles to fit Bob\\'s distribution')\n",
    "plt.grid(b=1, which='major', axis='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
